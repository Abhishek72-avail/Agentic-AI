{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd832cf3",
   "metadata": {},
   "source": [
    "# Building  Chatbot Which will Answer on Behalf of me "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4bafaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create  a chatbot . Install the required packages using:\n",
    "# uv add install openai gradio pypdf python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8367de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Placment\\AI\\Agentic-AI\n"
     ]
    }
   ],
   "source": [
    "#read the PDF file\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "print(project_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d3bccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parag Agrawal - Professional Profile\n",
      "Summary\n",
      "Parag Agrawal is an Indian-American software engineer and entrepreneur, best known for his tenure\n",
      "as the CEO of Twitter from November 2021 to October 2022. He was appointed CEO following Jack\n",
      "Dorsey's resignation but was dismissed after Elon Musk's acquisition of Twitter.\n",
      "Education and Early Career\n",
      "Agrawal holds a B.Tech in Computer Science and Engineering from the Indian Institute of\n",
      "Technology (IIT) Bombay. He then pursued a Ph.D. in Computer Science at Stanford University,\n",
      "where his research focused on uncertainty in data management and integration. Prior to his role at\n",
      "Twitter, he held research internships at Microsoft Research and Yahoo! Research.\n",
      "Career at Twitter\n",
      "Agrawal joined Twitter in 2011 as a software engineer and quickly rose through the ranks. In 2017,\n",
      "he was appointed Chief Technology Officer (CTO), overseeing Twitter's technical strategy and\n",
      "leading initiatives like Project Bluesky, aimed at developing a decentralized social media protocol.\n",
      "He succeeded Jack Dorsey as CEO in 2021, focusing on areas such as artificial intelligence,\n",
      "machine learning, and decentralization.\n",
      "Post-Twitter Venture: Parallel Web Systems\n",
      "After leaving Twitter, Agrawal co-founded Parallel Web Systems Inc., an AI startup that exited\n",
      "stealth mode in October 2024. The company has raised approximately $30 million in funding from\n",
      "investors like Khosla Ventures, Index Ventures, and First Round Capital. Parallel Web Systems\n",
      "aims to develop an API that enables AI systems to interact with web data, facilitating advanced AI\n",
      "operations on behalf of users. The startup is based in Palo Alto, California, and employs a team of\n",
      "around 10 individuals.\n",
      "Personal Life\n",
      "Agrawal is married to Vineeta Agarwala, a general partner at the venture capital firm AndreessenParag Agrawal - Professional Profile\n",
      "Horowitz, where she focuses on investments in biotech and health tech. The couple resides in San\n",
      "Francisco and has two children.\n"
     ]
    }
   ],
   "source": [
    "# read the PDF file\n",
    "filePath = project_root / \"Resourses\" / \"Profile.pdf\"\n",
    "PdfReader = PdfReader(filePath)\n",
    "prof_summary = \"\"\n",
    "for page in PdfReader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        prof_summary += text\n",
    "print(prof_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d097635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parag Agrawal leads a balanced life that blends his demanding career with a strong emphasis on family and personal interests. He is married to Vineeta Agarwala, a general partner at the venture capital firm Andreessen Horowitz, where she invests in biotech and health tech. Together, they reside in San Francisco and are raising two children. Despite his high-profile career, Parag values quality time with his family and enjoys nurturing curiosity both personally and professionally. Outside of work, he has interests in reading, mentoring young talent, and staying connected with his cultural roots. His personal life reflects a grounded and thoughtful approach, complementing his innovative professional journey.\n"
     ]
    }
   ],
   "source": [
    "#read the summary file\n",
    "summaryFilePath = project_root / \"Resourses\" / \"Summary.txt\"\n",
    "with open(summaryFilePath, \"r\") as file:\n",
    "    summary = file.read()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15df0b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base URL: https://api.deepseek.com\n",
      "API Key prefix: sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "\n",
    "openai_api_key = os.getenv(\"API_TOKEN\")\n",
    "deepseek_base_url = \"https://api.deepseek.com\"\n",
    "openai_python_client = OpenAI(api_key=openai_api_key, base_url=deepseek_base_url)\n",
    "\n",
    "print(f\"Base URL: {deepseek_base_url}\")\n",
    "if openai_api_key:\n",
    "    print(f\"API Key prefix: {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"API Key is not set. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd63bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'You are a helpful AI assistant named Agentic AI. \\nYou are designed to assist users with their questions and provide information based on the provided context.\\nYour responses should be concise, accurate, and relevant to the user\\'s queries.\\nYou have access to the following context:\\nParag Agrawal - Professional Profile\\nSummary\\nParag Agrawal is an Indian-American software engineer and entrepreneur, best known for his tenure\\nas the CEO of Twitter from November 2021 to October 2022. He was appointed CEO following Jack\\nDorsey\\'s resignation but was dismissed after Elon Musk\\'s acquisition of Twitter.\\nEducation and Early Career\\nAgrawal holds a B.Tech in Computer Science and Engineering from the Indian Institute of\\nTechnology (IIT) Bombay. He then pursued a Ph.D. in Computer Science at Stanford University,\\nwhere his research focused on uncertainty in data management and integration. Prior to his role at\\nTwitter, he held research internships at Microsoft Research and Yahoo! Research.\\nCareer at Twitter\\nAgrawal joined Twitter in 2011 as a software engineer and quickly rose through the ranks. In 2017,\\nhe was appointed Chief Technology Officer (CTO), overseeing Twitter\\'s technical strategy and\\nleading initiatives like Project Bluesky, aimed at developing a decentralized social media protocol.\\nHe succeeded Jack Dorsey as CEO in 2021, focusing on areas such as artificial intelligence,\\nmachine learning, and decentralization.\\nPost-Twitter Venture: Parallel Web Systems\\nAfter leaving Twitter, Agrawal co-founded Parallel Web Systems Inc., an AI startup that exited\\nstealth mode in October 2024. The company has raised approximately $30 million in funding from\\ninvestors like Khosla Ventures, Index Ventures, and First Round Capital. Parallel Web Systems\\naims to develop an API that enables AI systems to interact with web data, facilitating advanced AI\\noperations on behalf of users. The startup is based in Palo Alto, California, and employs a team of\\naround 10 individuals.\\nPersonal Life\\nAgrawal is married to Vineeta Agarwala, a general partner at the venture capital firm AndreessenParag Agrawal - Professional Profile\\nHorowitz, where she focuses on investments in biotech and health tech. The couple resides in San\\nFrancisco and has two children.\\nYou also have access to the following summary:\\nParag Agrawal leads a balanced life that blends his demanding career with a strong emphasis on family and personal interests. He is married to Vineeta Agarwala, a general partner at the venture capital firm Andreessen Horowitz, where she invests in biotech and health tech. Together, they reside in San Francisco and are raising two children. Despite his high-profile career, Parag values quality time with his family and enjoys nurturing curiosity both personally and professionally. Outside of work, he has interests in reading, mentoring young talent, and staying connected with his cultural roots. His personal life reflects a grounded and thoughtful approach, complementing his innovative professional journey.\\nYour task is to answer user questions based on the provided context and summary.\\nIf you do not know the answer, you should say \"I don\\'t know\".\\nYou should not make up answers or provide information that is not present in the context or summary.\\nYou should always respond in a helpful and informative manner.\\nYou should not provide any personal opinions or subjective statements.\\nYou should always strive to provide the most accurate and relevant information to the user.\\nYou should always be polite and respectful in your responses.\\nYou should always strive to provide the best possible user experience.\\nYou should always strive to provide the most accurate and relevant information to the user.\\nYou should always strive to provide the best possible user experience.\\n'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system_prompt \n",
    "\n",
    "name = \"Agentic AI\"\n",
    "\n",
    "system_prompt = { f\"\"\"You are a helpful AI assistant named {name}. \n",
    "You are designed to assist users with their questions and provide information based on the provided context.\n",
    "Your responses should be concise, accurate, and relevant to the user's queries.\n",
    "You have access to the following context:\n",
    "{prof_summary}\n",
    "You also have access to the following summary:\n",
    "{summary}\n",
    "Your task is to answer user questions based on the provided context and summary.\n",
    "If you do not know the answer, you should say \"I don't know\".\n",
    "You should not make up answers or provide information that is not present in the context or summary.\n",
    "You should always respond in a helpful and informative manner.\n",
    "You should not provide any personal opinions or subjective statements.\n",
    "You should always strive to provide the most accurate and relevant information to the user.\n",
    "You should always be polite and respectful in your responses.\n",
    "You should always strive to provide the best possible user experience.\n",
    "You should always strive to provide the most accurate and relevant information to the user.\n",
    "You should always strive to provide the best possible user experience.\n",
    "\"\"\" \n",
    "}\n",
    "# Initialize OpenAI client\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af3f1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create  a chatbot function\n",
    "def LiveChat(message, history): \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    response = openai_python_client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35284ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1729, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 907, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 545, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 917, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_23544\\2041267566.py\", line 5, in LiveChat\n",
      "    response = openai_python_client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1249, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1037, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****q3kA is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1729, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 907, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 545, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 917, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_23544\\2041267566.py\", line 5, in LiveChat\n",
      "    response = openai_python_client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1249, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1037, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****q3kA is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1729, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 907, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 545, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 917, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_23544\\2041267566.py\", line 5, in LiveChat\n",
      "    response = openai_python_client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1249, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Placment\\AI\\Agentic-AI\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1037, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****q3kA is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(LiveChat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
